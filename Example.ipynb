{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595b1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "def txt_to_csv(file_name):\n",
    "    \"\"\"\n",
    "    A function to change .txt file to .csv file\n",
    "\n",
    "    Parameters:\n",
    "    file_name (str): the name of the .txt file\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    #data = pd.read_csv(f'data_txt\\\\{file_name}', sep=\",\", encoding='utf-8', dtype='str')\n",
    "    data = pd.read_csv(f'txt\\\\{file_name}', sep=\",\", encoding='utf-8', dtype='str')\n",
    "    data.to_csv(f'data_csv\\\\{file_name[:-4]}.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# see all the files in the folder 'data_txt'\n",
    "def see_files(foldername):\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    files = [f for f in listdir(foldername) if isfile(join(foldername, f))]\n",
    "    # change to list of file names as string\n",
    "    files = [str(file) for file in files]\n",
    "    \n",
    "    return files\n",
    "\n",
    "# define the columns to keep and their possible name variations\n",
    "columns = [{'region': ['reg']}, \n",
    "           {'province': ['cwd', 'cwt']}, \n",
    "           #'amp', \n",
    "           #'tmb', \n",
    "           {'municipal': ['area']}, \n",
    "           #'ea', \n",
    "           #'vil', \n",
    "           #'psu_no', \n",
    "           #'ea_set', \n",
    "           #'samset', \n",
    "           {'month': ['month', 'mounth']}, \n",
    "           {'year': ['yr']}, \n",
    "           #'hh_no', \n",
    "           #'tpye', \n",
    "           #'member', \n",
    "           #'listing', \n",
    "           #'enum', \n",
    "           #'no', \n",
    "           {'relation': ['ralation', 'rela']}, \n",
    "           {'male': ['sex']}, \n",
    "           {'age': ['age']}, \n",
    "           {'marital': ['marital']}, \n",
    "           {'studying': ['grade_a']}, \n",
    "           {'edu_level': ['grade_b']}, \n",
    "           {'edu_field': ['subject']}, \n",
    "           {'wk_7day': ['wk_7day', 'work']}, \n",
    "           {'receive': ['receive', 'receiv']}, \n",
    "           {'return': ['return']}, \n",
    "           {'absent': ['absent']}, \n",
    "           {'seeking': ['seeking', 'seek']}, \n",
    "           {'method': ['method']}, \n",
    "           {'available': ['aviala', 'avai']}, \n",
    "           {'re_unavailable': ['re_una', 're_unavail']}, \n",
    "           {'reno_se': ['reno_se', 're_no_seek']}, \n",
    "           {'dr_seek': ['dr_se', 'dr_see']}, \n",
    "           {'ever_wk': ['ever_wk']}, \n",
    "           {'re_unem': ['re_unem']}, \n",
    "           {'dr_unem': ['dr_unem']}, \n",
    "           #'occup1', \n",
    "           #'occup2', \n",
    "           #'occup3', \n",
    "           {'occupation': ['occup']}, \n",
    "           #'ind1', \n",
    "           #'ind2', \n",
    "           #'ind3', \n",
    "           #'ind4', \n",
    "           {'industry': ['indus']}, \n",
    "           {'position': ['status']}, \n",
    "           {'firm_size': ['size', 'size_']}, \n",
    "           {'main_hr': ['main_hr']}, \n",
    "           {'part_time_hr': ['other_hr']}, \n",
    "           {'total_hr': ['tot_hr']}, \n",
    "           {'more_wk': ['more_wk']}, \n",
    "           {'more_hr': ['more_hr']}, \n",
    "           {'finding': ['finding']}, \n",
    "           {'re_nomore': ['re_no', 're_nomore', 're_nom']}, \n",
    "           {'wage_type': ['wage_ty', 'wg_ty']}, \n",
    "           {'amount': ['amount', 'amoun']}, \n",
    "           {'wage_per_month': ['approx']}, \n",
    "           {'wage_bonus': ['bonus']}, \n",
    "           {'wage_ot': ['ot']}, \n",
    "           {'other_income': ['oth_mon', 'oth_money']}, \n",
    "           {'exp_food': ['food']}, \n",
    "           {'exp_cloth': ['cloth', 'colth']}, \n",
    "           {'exp_house': ['house']}, \n",
    "           {'exp_others': ['oth_thi', 'oth_th', 'oth_thing']}, \n",
    "           #'lst_m', \n",
    "           {'re_wk': ['re_wk']}, \n",
    "           {'re_ed': ['re_ed']}, \n",
    "           {'weight': ['weight', 'wgt', 'wgt_cwt']} \n",
    "           #'who', \n",
    "           #'age_g', \n",
    "           #'age_g1', \n",
    "           #'edu', \n",
    "           #'edu1', \n",
    "           #'wkcode', \n",
    "           #'wksta', \n",
    "           #'wksta1', \n",
    "           #'PROVINCE', \n",
    "           #'indus_g', \n",
    "           #'indus_g1', \n",
    "           #'indus_g2', \n",
    "           #'indus_g3', \n",
    "           #'totalhr', \n",
    "           #'g_hr', \n",
    "           #'timeseries', \n",
    "           #'year', \n",
    "           #'quarter', \n",
    "           #'minwgae', \n",
    "           #'wage_day', \n",
    "           #'_v1', \n",
    "           #'low_wage', \n",
    "           #'new_wage'\n",
    "           ]\n",
    "\n",
    "# get a list of all keys from list of dict 'columns'\n",
    "column_master = [list(d.keys())[0] for d in columns]\n",
    "\n",
    "\n",
    "def clean_data(years, quarters, columns, column_master):\n",
    "    for year in years:\n",
    "        for quarter in quarters:\n",
    "            try:\n",
    "                #df = pd.read_csv(f'data_csv/LFS_{year}q{quarter}.csv', encoding='utf-8', dtype='str')\n",
    "                df = pd.read_csv(f'data_csv/LFS_{year}q{quarter}.csv', encoding='utf-8', dtype='str')\n",
    "                # change all headers to lowercase\n",
    "                df.columns = df.columns.str.lower()\n",
    "                for column in columns:\n",
    "                    for key, value in column.items():\n",
    "                        test = 0\n",
    "                        for v in value:\n",
    "                            if v in df.columns:\n",
    "                                df.rename(columns={v: key}, inplace=True)\n",
    "                                test = 1\n",
    "                                if test == 0:\n",
    "                                    print(f'{key} not found in {year}q{quarter}')\n",
    "                                    break\n",
    "                # if df contains all columns in 'column_master' then filter out only those columns, \n",
    "                # but if not then create those missing columns and merge with the original df with NaN values, also print out what columns are missing\n",
    "                if set(column_master).issubset(df.columns):\n",
    "                    df = df[column_master]\n",
    "                    # drop duplicate columns\n",
    "                    df = df.loc[:,~df.columns.duplicated()]\n",
    "                else:\n",
    "                    missing_columns = list(set(column_master) - set(df.columns))\n",
    "                    print(f'{year}q{quarter} has some missing columns: {missing_columns}')\n",
    "                    for col in missing_columns:\n",
    "                        df[col] = None\n",
    "                    df = df.loc[:,~df.columns.duplicated()]\n",
    "                    df = df[column_master]\n",
    "                # remove rows with all empty values\n",
    "                df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "                df.to_csv(f'data_csv_cleaned/LFS_{year}q{quarter}.csv', index=False, encoding='utf-8')\n",
    "                print(f'{year}q{quarter} done')\n",
    "            except Exception as e:\n",
    "                print(f\"{year}q{quarter} -- error occurred: {e}\")\n",
    "\n",
    "\n",
    "def get_years_list(start_year, end_year):\n",
    "    years = [str(year) for year in range(start_year, end_year+1)]\n",
    "    return years"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
